{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_loader.data_generator import DataGenerator\n",
    "from models.gan import GAN\n",
    "from trainers.gan_trainer import GANTrainer\n",
    "from utils.config import process_config\n",
    "from utils.logger import Logger\n",
    "from utils.utils import get_args\n",
    "from utils.dirs import create_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "init = tf.global_variables_initializer()\n",
    "from models.gankeras import GanKeras\n",
    "from utils.config import process_config\n",
    "config_file = 'configs/gan.json'\n",
    "config = process_config(config_file,\"model_test\")\n",
    "create_dirs(\n",
    "        [\n",
    "            config.log.summary_dir,\n",
    "            config.log.checkpoint_dir,\n",
    "            config.log.step_generation_dir,\n",
    "            config.log.log_file_dir,\n",
    "        ]\n",
    "    )\n",
    "mod = GanKeras(config)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #mod.load(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 14, 14, 32)        832       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 64)          51264     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 3137      \n",
      "=================================================================\n",
      "Total params: 55,233\n",
      "Trainable params: 55,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment parameters are already stored\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "init = tf.global_variables_initializer()\n",
    "from models.gan_tf import GAN_TF\n",
    "from utils.config import process_config\n",
    "config_file = 'configs/gan_tf.json'\n",
    "config = process_config(config_file,\"gan_model_test\")\n",
    "config\n",
    "mod = GAN_TF(config)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #mod.load(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'DCGAN/Generator/g_dense/kernel:0' shape=(100, 12544) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_1/gamma:0' shape=(12544,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_1/beta:0' shape=(12544,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_conv2dtr_1/kernel:0' shape=(5, 5, 128, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_2/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_2/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_conv2dtr_2/kernel:0' shape=(5, 5, 128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_3/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_3/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_conv2dtr_3/kernel:0' shape=(5, 5, 128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_4/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_4/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_conv2dtr_4/kernel:0' shape=(5, 5, 1, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_conv1/kernel:0' shape=(5, 5, 1, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_conv1/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_bn_1/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_bn_1/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_conv_2/kernel:0' shape=(5, 5, 128, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_conv_2/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_bn_2/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_bn_2/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_conv_3/kernel:0' shape=(5, 5, 64, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_conv_3/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_bn_3/gamma:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_bn_3/beta:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_dense/kernel:0' shape=(1568, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_dense/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'DCGAN/Discriminator/d_conv1/kernel:0' shape=(5, 5, 1, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_conv1/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_bn_1/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_bn_1/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_conv_2/kernel:0' shape=(5, 5, 128, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_conv_2/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_bn_2/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_bn_2/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_conv_3/kernel:0' shape=(5, 5, 64, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_conv_3/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_bn_3/gamma:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_bn_3/beta:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_dense/kernel:0' shape=(1568, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Discriminator/d_dense/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.discriminator_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'DCGAN/Generator/g_bn_1/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Generator/g_bn_1/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Generator/g_bn_2/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Generator/g_bn_2/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Generator/g_bn_3/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Generator/g_bn_3/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Generator/g_bn_4/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Generator/g_bn_4/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Generator_1/g_bn_1/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Generator_1/g_bn_1/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Generator_1/g_bn_2/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Generator_1/g_bn_2/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Generator_1/g_bn_3/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Generator_1/g_bn_3/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Generator_1/g_bn_4/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Generator_1/g_bn_4/AssignMovingAvg_1' type=AssignSub>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.gen_update_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'DCGAN/Generator/g_dense/kernel:0' shape=(100, 12544) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_1/gamma:0' shape=(12544,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_1/beta:0' shape=(12544,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_conv2dtr_1/kernel:0' shape=(5, 5, 128, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_2/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_2/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_conv2dtr_2/kernel:0' shape=(5, 5, 128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_3/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_3/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_conv2dtr_3/kernel:0' shape=(5, 5, 128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_4/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_bn_4/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DCGAN/Generator/g_conv2dtr_4/kernel:0' shape=(5, 5, 1, 128) dtype=float32_ref>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.generator_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'DCGAN/Discriminator/d_bn_1/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Discriminator/d_bn_1/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Discriminator/d_bn_2/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Discriminator/d_bn_2/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Discriminator/d_bn_3/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Discriminator/d_bn_3/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Discriminator_1/d_bn_1/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Discriminator_1/d_bn_1/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Discriminator_1/d_bn_2/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Discriminator_1/d_bn_2/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Discriminator_1/d_bn_3/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'DCGAN/Discriminator_1/d_bn_3/AssignMovingAvg_1' type=AssignSub>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.disc_update_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "init = tf.global_variables_initializer()\n",
    "from models.aladkeras import ALADKeras\n",
    "from utils.config import process_config\n",
    "config_file = 'configs/alad.json'\n",
    "config = process_config(config_file,\"alad_model_test\")\n",
    "mod = ALADKeras(config)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #mod.load(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "from tensorflow.keras.layers import Input,Dense, Conv2D, Conv2DTranspose, BatchNormalization, LeakyReLU, ReLU, Concatenate, Flatten\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 16, 16, 64)        1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 8, 8, 128)         131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 4, 4, 256)         524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 2, 2, 256)         1048832   \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 1, 1, 100)         409700    \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 1, 1, 100)         400       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)   (None, 1, 1, 100)         0         \n",
      "=================================================================\n",
      "Total params: 2,118,580\n",
      "Trainable params: 2,116,972\n",
      "Non-trainable params: 1,608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=[32, 32, 1])\n",
    "# Encoder\n",
    "ly1 = Conv2D(filters=64,kernel_size=4,strides=2,padding=\"same\")(inp)\n",
    "ly1 = BatchNormalization()(ly1)\n",
    "ly1 = LeakyReLU()(ly1) # 16 x 16 x 64\n",
    "\n",
    "ly2 = Conv2D(filters=128,kernel_size=4,strides=2,padding=\"same\")(ly1)\n",
    "ly2 = BatchNormalization()(ly2)\n",
    "ly2 = LeakyReLU()(ly2) # 8 x 8 x 128\n",
    "\n",
    "ly3 = Conv2D(filters=256,kernel_size=4,strides=2,padding=\"same\")(ly2)\n",
    "ly3 = BatchNormalization()(ly3)\n",
    "ly3 = LeakyReLU()(ly3) # 4 x 4 x 256\n",
    "\n",
    "ly4 = Conv2D(filters=256,kernel_size=4,strides=2,padding=\"same\")(ly3)\n",
    "ly4 = BatchNormalization()(ly4)\n",
    "ly4 = LeakyReLU()(ly4) # 4 x 4 x 256\n",
    "ly4 = Conv2D(filters=100,kernel_size=4,strides=2,padding=\"same\")(ly4)\n",
    "ly4 = BatchNormalization()(ly4)\n",
    "ly4 = LeakyReLU()(ly4) # 4 x 4 x 256\n",
    "# ly4 = Conv2D(filters=512,kernel_size=5,strides=2,padding=\"same\")(ly3)\n",
    "# ly4 = BatchNormalization()(ly4)\n",
    "# ly4 = LeakyReLU()(ly4) # 2 x 2 x 512\n",
    "\n",
    "ly5 = Conv2DTranspose(filters=1,kernel_size=5,strides=1,padding=\"same\")(ly3) # 1 x 1 x 512\n",
    "\n",
    "# Decoder\n",
    "#inp = Input(shape=[1, 1, 256])\n",
    "ly6 = Conv2DTranspose(filters=512,kernel_size=5,strides=2,padding=\"same\")(ly5)\n",
    "ly6 = BatchNormalization()(ly6)\n",
    "ly6 = ReLU()(ly6)\n",
    "#ly6_m = Concatenate(axis=-1)([ly4, ly6])\n",
    "\n",
    "\n",
    "ly7 = Conv2DTranspose(filters=256,kernel_size=5,strides=2,padding=\"valid\")(ly6)\n",
    "ly7 = BatchNormalization()(ly7)\n",
    "ly7 = ReLU()(ly7)\n",
    "#ly7_m = Concatenate(axis=-1)([ly3, ly7])\n",
    "\n",
    "ly8 = Conv2DTranspose(filters=128,kernel_size=5,strides=2,padding=\"same\")(ly7)\n",
    "ly8 = BatchNormalization()(ly8)\n",
    "ly8 = ReLU()(ly8)\n",
    "#ly8_m = Concatenate(axis=-1)([ly2, ly8])\n",
    "\n",
    "\n",
    "# ly9 = Conv2DTranspose(filters=64,kernel_size=5,strides=2,padding=\"same\")(ly8)\n",
    "# ly9 = BatchNormalization()(ly9)\n",
    "# ly9 = ReLU()(ly9)\n",
    "# #ly9_m = Concatenate(axis=-1)([ly1, ly9])\n",
    "\n",
    "\n",
    "ly10 = Conv2DTranspose(filters=1,kernel_size=5,strides=2,padding=\"same\")(ly5)\n",
    "\n",
    "mod = Model(inputs=inp,outputs=ly4)\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_count = int(numpy.sum([numpy.prod(numpy.array([s if isinstance(s, int) else 1 for s in l.output_shape])) for l in mod.layers]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993280"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'ALAD/Encoder_Model/layer_1/conv/kernel:0' shape=(4, 4, 1, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Encoder_Model/layer_1/conv/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Encoder_Model/layer_1/bn/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Encoder_Model/layer_1/bn/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Encoder_Model/layer_2/conv/kernel:0' shape=(4, 4, 128, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Encoder_Model/layer_2/conv/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Encoder_Model/layer_2/bn/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Encoder_Model/layer_2/bn/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Encoder_Model/layer_3/conv/kernel:0' shape=(4, 4, 256, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Encoder_Model/layer_3/conv/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Encoder_Model/layer_3/bn/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Encoder_Model/layer_3/bn/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Encoder_Model/layer_4/conv/kernel:0' shape=(4, 4, 512, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Encoder_Model/layer_4/conv/bias:0' shape=(100,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.evars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'ALAD/Discriminator_Model_xz/x_layer_1/conv1/kernel:0' shape=(4, 4, 1, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/x_layer_1/conv1/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/x_layer_2/conv2/kernel:0' shape=(4, 4, 1, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/x_layer_2/conv2/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/x_layer_2/tconv2/bn/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/x_layer_2/tconv2/bn/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/x_layer_3/conv2/kernel:0' shape=(4, 4, 1, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/x_layer_3/conv2/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/x_layer_3/tconv3/bn/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/x_layer_3/tconv3/bn/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/z_layer_1/conv/kernel:0' shape=(4, 4, 100, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/z_layer_1/conv/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/z_layer_2/conv/kernel:0' shape=(4, 4, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/z_layer_2/conv/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/y_layer_1/conv/kernel:0' shape=(1, 1, 8704, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/y_layer_1/conv/bias:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/y_layer_2/conv/kernel:0' shape=(1, 1, 1024, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xz/y_layer_2/conv/bias:0' shape=(1024,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.dxzvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'ALAD/Discriminator_Model_xx/layer_1/conv1/kernel:0' shape=(5, 5, 1, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xx/layer_1/conv1/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xx/layer_2/conv2/kernel:0' shape=(5, 5, 64, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xx/layer_2/conv2/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xx/layer_3/fc/kernel:0' shape=(12544, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_xx/layer_3/fc/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.dxxvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'ALAD/Discriminator_Model_zz/y_layer_1/fc/kernel:0' shape=(200, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_zz/y_layer_1/fc/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_zz/y_layer_2/fc/kernel:0' shape=(64, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_zz/y_layer_2/fc/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_zz/y_layer_3/fc/kernel:0' shape=(32, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ALAD/Discriminator_Model_zz/y_layer_3/fc/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.dzzvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'ALAD/Generator_Model/layer_1/dense/bn/cond_2/Merge' type=Merge>,\n",
       " <tf.Operation 'ALAD/Generator_Model/layer_1/dense/bn/cond_3/Merge' type=Merge>,\n",
       " <tf.Operation 'ALAD/Generator_Model/layer_2/tconv1/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Generator_Model/layer_2/tconv1/bn/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Generator_Model/layer_3/tconv2/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Generator_Model/layer_3/tconv2/bn/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Generator_Model/layer_4/tconv3/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Generator_Model/layer_4/tconv3/bn/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Generator_Model_1/layer_1/dense/bn/cond_2/Merge' type=Merge>,\n",
       " <tf.Operation 'ALAD/Generator_Model_1/layer_1/dense/bn/cond_3/Merge' type=Merge>,\n",
       " <tf.Operation 'ALAD/Generator_Model_1/layer_2/tconv1/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Generator_Model_1/layer_2/tconv1/bn/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Generator_Model_1/layer_3/tconv2/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Generator_Model_1/layer_3/tconv2/bn/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Generator_Model_1/layer_4/tconv3/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Generator_Model_1/layer_4/tconv3/bn/AssignMovingAvg_1' type=AssignSub>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.update_ops_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'ALAD/Encoder_Model/layer_1/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Encoder_Model/layer_1/bn/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Encoder_Model/layer_2/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Encoder_Model/layer_2/bn/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Encoder_Model/layer_3/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Encoder_Model/layer_3/bn/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Encoder_Model_1/layer_1/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Encoder_Model_1/layer_1/bn/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Encoder_Model_1/layer_2/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Encoder_Model_1/layer_2/bn/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Encoder_Model_1/layer_3/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Encoder_Model_1/layer_3/bn/AssignMovingAvg_1' type=AssignSub>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.update_ops_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'ALAD/Discriminator_Model_xz/x_layer_2/tconv2/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Discriminator_Model_xz/x_layer_2/tconv2/bn/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Discriminator_Model_xz/x_layer_3/tconv3/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Discriminator_Model_xz/x_layer_3/tconv3/bn/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Discriminator_Model_xz_1/x_layer_2/tconv2/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Discriminator_Model_xz_1/x_layer_2/tconv2/bn/AssignMovingAvg_1' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Discriminator_Model_xz_1/x_layer_3/tconv3/bn/AssignMovingAvg' type=AssignSub>,\n",
       " <tf.Operation 'ALAD/Discriminator_Model_xz_1/x_layer_3/tconv3/bn/AssignMovingAvg_1' type=AssignSub>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.update_ops_dis_xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.update_ops_dis_xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.update_ops_dis_zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "FORMATTER = logging.Formatter(\"%(asctime)s — %(name)s — %(levelname)s — %(message)s\")\n",
    "LOG_FILE = \"my_app.log\"\n",
    "\n",
    "def get_console_handler():\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(FORMATTER)\n",
    "    return console_handler\n",
    "def get_file_handler():\n",
    "    file_handler = logging.FileHandler(LOG_FILE)\n",
    "    file_handler.setFormatter(FORMATTER)\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    return file_handler\n",
    "def get_logger(logger_name):\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(logging.DEBUG) # better to have too much log than not enough\n",
    "    logger.addHandler(get_console_handler())\n",
    "    logger.addHandler(get_file_handler())\n",
    "    # with this pattern, it's rarely necessary to propagate the error up to parent\n",
    "    logger.propagate = False\n",
    "    return logger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_logger(\"haha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-08 16:15:30,904 — haha — INFO — test\n"
     ]
    }
   ],
   "source": [
    "test.info(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-08 16:15:43,771 — haha — DEBUG — value is 5\n"
     ]
    }
   ],
   "source": [
    "test.debug(\"value is {}\".format(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-08 16:15:56,428 — haha — INFO — hmm thats odd\n"
     ]
    }
   ],
   "source": [
    "test.info(\"hmm thats odd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment parameters are already stored\n",
      "2019-04-08 17:54:18,248 — utils.DataLoader — INFO — Train Dataset is already populated.\n",
      "2019-04-08 17:54:18,248 — utils.DataLoader — INFO — Train Dataset is already populated.\n",
      "2019-04-08 17:54:18,248 — utils.DataLoader — INFO — Train Dataset is already populated.\n",
      "2019-04-08 17:54:18,251 — utils.DataLoader — INFO — Test Dataset is already populated\n",
      "2019-04-08 17:54:18,251 — utils.DataLoader — INFO — Test Dataset is already populated\n",
      "2019-04-08 17:54:18,251 — utils.DataLoader — INFO — Test Dataset is already populated\n",
      "2019-04-08 17:54:18,254 — data_loader.data_generator — INFO — Data is loading...\n",
      "2019-04-08 17:54:18,254 — data_loader.data_generator — INFO — Data is loading...\n",
      "2019-04-08 17:54:18,254 — data_loader.data_generator — INFO — Data is loading...\n",
      "2019-04-08 17:54:18,254 — data_loader.data_generator — INFO — Data is loading...\n",
      "2019-04-08 17:54:18,741 — utils.DataLoader — INFO — Train Dataset is Loaded\n",
      "2019-04-08 17:54:18,741 — utils.DataLoader — INFO — Train Dataset is Loaded\n",
      "2019-04-08 17:54:18,741 — utils.DataLoader — INFO — Train Dataset is Loaded\n",
      "(36,) (36, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "init = tf.global_variables_initializer()\n",
    "from models.aladkeras import ALADKeras\n",
    "from utils.config import process_config\n",
    "config_file = 'configs/alad.json'\n",
    "config = process_config(config_file, \"alad_test\")\n",
    "from data_loader.data_generator import DataGenerator\n",
    "data = DataGenerator(config)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(data.test_iterator.initializer)\n",
    "    print(sess.run(data.test_label).shape,sess.run(data.test_image).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
